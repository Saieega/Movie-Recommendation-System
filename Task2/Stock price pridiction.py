# -*- coding: utf-8 -*-
"""Task-2

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1MvmNAFwQi1j188hNMzn_K51u_X7Od534
"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import MinMaxScaler
from sklearn.linear_model import LinearRegression
from sklearn.ensemble import RandomForestRegressor
from sklearn.metrics import mean_squared_error

import yfinance as yf
data = yf.download('INFY.NS', start='2015-01-01', end='2024-01-01')
print (data.head(10))

data.columns = [col[0] for col in data.columns]

df = data[['Close']].copy()

scaler= MinMaxScaler()

df['Close']=scaler.fit_transform(df[['Close']])

def create_dataset(series, look_back=10):
    X, y = [], []
    for i in range(len(series) - look_back):
        X.append(series[i:i + look_back])
        y.append(series[i + look_back])
    return np.array(X), np.array(y)
values = df['Close'].values
look_back = 10
X, y = create_dataset(values, look_back)

print("X shape:", X.shape)
print("y shape:", y.shape)

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, shuffle=False)

print("X_train shape:", X_train.shape)
print("X_test shape:", X_test.shape)

lr_model = LinearRegression()
lr_model.fit(X_train, y_train)
lr_preds = lr_model.predict(X_test)

rf_model = RandomForestRegressor(n_estimators=100, random_state=42)
rf_model.fit(X_train, y_train)
rf_preds = rf_model.predict(X_test)

from sklearn.metrics import mean_squared_error
import numpy as np

lr_rmse = np.sqrt(mean_squared_error(y_test, lr_preds))
rf_rmse = np.sqrt(mean_squared_error(y_test, rf_preds))

print(f"Linear Regression RMSE: {lr_rmse}")
print(f"Random Forest RMSE: {rf_rmse}")

import matplotlib.pyplot as plt

y_test_reshaped = y_test.reshape(-1, 1)
lr_preds_reshaped = lr_preds.reshape(-1, 1)
rf_preds_reshaped = rf_preds.reshape(-1, 1)

y_test_actual = scaler.inverse_transform(y_test_reshaped)
lr_preds_actual = scaler.inverse_transform(lr_preds_reshaped)
rf_preds_actual = scaler.inverse_transform(rf_preds_reshaped)

plt.figure(figsize=(14,6))
plt.plot(y_test_actual, label='Actual INFY Price', color='black')
plt.plot(lr_preds_actual, label='Linear Regression', linestyle='--', color='blue')
plt.plot(rf_preds_actual, label='Random Forest', linestyle='--', color='green')
plt.title('INFY Stock Price Prediction (Actual vs Predicted)')
plt.xlabel('Days')
plt.ylabel('Price (INR)')
plt.legend()
plt.grid()
plt.tight_layout()
plt.show()

#Which gives us the insight that random forest is deviating from the actula price where Linear regression is as close as to actual price so Linear regression model is performing better.

#Now we perform on lstm model

X_train_lstm = X_train.reshape((X_train.shape[0], X_train.shape[1], 1))
X_test_lstm = X_test.reshape((X_test.shape[0], X_test.shape[1], 1))

from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import LSTM, Dense

model = Sequential()
model.add(LSTM(50, return_sequences=False, input_shape=(X_train_lstm.shape[1], 1)))
model.add(Dense(1))

model.compile(optimizer='adam', loss='mean_squared_error')

history = model.fit(X_train_lstm, y_train, epochs=20, batch_size=32, validation_split=0.1)

lstm_preds = model.predict(X_test_lstm)

lstm_preds_actual = scaler.inverse_transform(lstm_preds)
y_test_actual = scaler.inverse_transform(y_test.reshape(-1, 1))

plt.figure(figsize=(14,6))
plt.plot(y_test_actual, label='Actual INFY Price', color='black')
plt.plot(lstm_preds_actual, label='LSTM Prediction', linestyle='--', color='orange')
plt.title('INFY Stock Price Prediction using LSTM')
plt.xlabel('Days')
plt.ylabel('Price in (INR)')
plt.legend()
plt.grid()
plt.tight_layout()
plt.show()

test_loss = model.evaluate(X_test_lstm, y_test, verbose=1)
print("Test MSE Loss (scaled):", test_loss)

